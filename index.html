<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Arun Madhusudhanan</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<h1><a href="index.html">We are infinite!</a></h1>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<div class="inner">
							<h2>Menu</h2>
							<ul class="links">
								<!-- <li><a href="index.html">Home</a></li> -->
								<li><a href="#one">About Me</a></li>
								<li><a href="#two">Projects</a></li>
								<li><a href="#three">Work Experience</a></li>
								<li><a href="#four">Publications</a></li>
								<!-- <li><a href="#">Log In</a></li>
								<li><a href="#">Sign Up</a></li> -->
							</ul>
							<a href="#" class="close">Close</a>
						</div>
					</nav>

				<!-- Banner -->
					<section id="banner">
						<div class="inner">
							<div class="logo"><span class="icon fa-gem"></span></div>
							<h2>Arun Madhusdhanan</h2>
							<p>Graduate Student | Robotics | Machine Learning | Ex - Machine Learning Engineer Co-op @ Festo | Ex- ExxonMobil </p>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
								   <li><a href="https://www.linkedin.com/in/arun-m1/" target="_blank" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
								   <li><a href="mailto:madhusudhanan.a@northeastern.edu" target="_blank" class="icon solid alt fa-envelope"><span class="label">Outlook</span></a></li>
								   <li><a href="https://github.com/arunmadhusud" target="_blank" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							 </section>
						</div>
						
					</section>

				<!-- Wrapper -->
					<section id="wrapper">

						<!-- One -->
							<section id="one" class="wrapper spotlight style1">
								<div class="inner">
									<a class="image"><img src="images/DP.png" alt="" /></a>
									<div class="content" style="text-align: justify;">
										<h2 class="major">ABOUT ME</h2>
										<p>Hello there! I'm a graduate student in Robotics at Northeastern University, currently working as a Teaching Assistant for the Pattern Recognition and Computer Vision course. I have a strong background in Machine Learning/Deep Learning and Computer Vision, with practical experience gained during my co-op as a Machine Learning Engineer at Festo. My past projects include creating a 3D object classification system using partial point clouds, implementing Optical flow Estimation for facial motion tracking, and developing a Sensor Fusion system that uses GPS, IMU, and camera for state estimation.

											Prior to my studies, I worked in the oil and gas industry at ExxonMobil, where I gained valuable experience in project management and problem solving. I am excited to now be pursuing a career in robotics and am eager to apply my skills and experience to this exciting and constantly evolving field.
											
											As a motivated and hardworking individual, I am confident in my ability to make a positive contribution to any team. I am open to new challenges and am always looking for opportunities to learn and grow.
											
											I am excited to connect with others in the robotics community. Feel free to reach out to me if you have any questions.</p>
										<div style="text-align: right;">
											<!--open in new tab-->											
											<a href="pdf/resume.pdf" target="_blank" class="special">Resume</a>
									</div>
								</div>
							</section>

						<!-- Two -->
							<!-- <section id="two" class="wrapper alt spotlight style2">
								<div class="inner">
									<a href="#" class="image"><img src="images/pic02.jpg" alt="" /></a>
									<div class="content">
										<h2 class="major">Tempus adipiscing</h2>
										<p>Lorem ipsum dolor sit amet, etiam lorem adipiscing elit. Cras turpis ante, nullam sit amet turpis non, sollicitudin posuere urna. Mauris id tellus arcu. Nunc vehicula id nulla dignissim dapibus. Nullam ultrices, neque et faucibus viverra, ex nulla cursus.</p>
										<a href="#" class="special">Learn more</a>
									</div>
								</div>
							</section> -->

						<!-- Three -->
							<!-- <section id="three" class="wrapper spotlight style3">
								<div class="inner">
									<a href="#" class="image"><img src="images/pic03.jpg" alt="" /></a>
									<div class="content">
										<h2 class="major">Nullam dignissim</h2>
										<p>Lorem ipsum dolor sit amet, etiam lorem adipiscing elit. Cras turpis ante, nullam sit amet turpis non, sollicitudin posuere urna. Mauris id tellus arcu. Nunc vehicula id nulla dignissim dapibus. Nullam ultrices, neque et faucibus viverra, ex nulla cursus.</p>
										<a href="#" class="special">Learn more</a>
									</div>
								</div>
							</section> -->

						<!-- Four -->
							<section id="two" class="wrapper alt style1">
								<div class="inner">
									<h2 class="major">Recent Projects</h2>
									<!-- <p>Cras mattis ante fermentum, malesuada neque vitae, eleifend erat. Phasellus non pulvinar erat. Fusce tincidunt, nisl eget mattis egestas, purus ipsum consequat orci, sit amet lobortis lorem lacus in tellus. Sed ac elementum arcu. Quisque placerat auctor laoreet.</p> -->
									<section class="features">
										<article>
											<a href="pdf/Optical_Flow_Comparison.pdf" target="_blank"  class="image"><img src="images/Optical_Flow.png" alt="" /></a>
											<h3 class="major">Optical Flow Estimation</h3>
											<p style="text-align: justify;">Optical flow estimation has found applications in various computer vision applications like object detection and tracking, movement detection, robot navigation and visual odometry. 
												This project presents a comprehensive study comparing the performance of both the classical and deep learning approaches for estimating dense optical flow. We used the Farneback method as a representative of classical techniques and FlowNet 2.0 as a representative of deep learning-based methods. Our experimental results highlight performance comparison of both the methods on a defined dataset using appropriate metrics - L1 error, Average end point error and Average angular error. The results show that FlowNet 2.0 provides significantly better results than Farneback Algorithm. </p>
											<!-- <a href="#" class="special">Learn more</a> -->
											<div style="display: flex; justify-content: space-between;">
												<a href="pdf/Optical_Flow_Comparison.pdf" target="_blank"  class="special" style="margin-right: 10px;">Report</a>
												<a href="https://github.com/arunmadhusud/Optical-Flow-Estimation" target="_blank" class="special">GitHub</a>
											</div>
										</article>
										<article>
											<a href="pdf/3D_Object_Classification.pdf" target="_blank"  class="image"><img src="images/3D_Object_Classification.png" alt="" /></a>
											<h3 class="major">3D Object Detection From Partial Point Clouds</h3>
											<p style="text-align: justify;">Point clouds are widely used as geometric data in various deep learning tasks like object detection and segmentation. However, in real-world scenarios, partial point clouds are often encountered due to limitations in sensors, occlusions, and other factors. The classification of objects from partial point clouds is a difficult task because of the sparsity, noise, and lack of complete representation of objects. This project aims to create a 3D object classification system that can classify objects from partial point clouds. To overcome the challenges, the GRNet neural network architecture is used to predict the missing data and complete the partial point clouds, which are then processed by PointNet, a deep learning framework that directly handles raw point clouds for object classification. The proposed method in this project performs equally or better than SOTA PointNet++.</p>
											<div style="display: flex; justify-content: space-between;">
												<a href="pdf/3D_Object_Classification.pdf" target="_blank"  class="special" style="margin-right: 10px;">Report</a>
												<a href="https://github.com/arunmadhusud/3D-Object-Detection-From-Partial-Point-Clouds" target="_blank" class="special">GitHub</a>
											</div>
										</article>
										<article>
											<a href="pdf/MNIST_digit_recognition.pdf" target="_blank"  class="image"><img src="images/MNIST_cropped.png" alt="" /></a>
											<h3 class="major">MNIST Digit Recognition</h3>
											<p style="text-align: justify;">
												This project involved the development and training of a neural network for recognizing handwritten digits in the MNIST dataset using PyTorch. The network's performance was evaluated on both test data and custom inputs. Subsequently, the first layers of the network were analyzed to better understand how they process data. The network was further modified and trained to recognize Greek letters. Various aspects of the network were experimented with, and their impact on performance was evaluated. A live digit recognition system based on the network was implemented, and the first layer of the network was replaced with a Gabor filter bank to assess its impact on performance.</p>
											<div style="display: flex; justify-content: space-between;">	
												<a href="pdf/MNIST_digit_recognition.pdf" target="_blank"  class="special" style="margin-right: 10px;">Report</a>											
												<a href="https://github.com/arunmadhusud/Recognition-using-Deep-Networks" target="_blank" class="special">GitHub</a>
											</div>
										</article>
										<article>
											<a href="pdf/Camera_claibration_and_AR.pdf" target="_blank"  class="image"><img src="images/AR Demo.png" alt="" /></a>
											<h3 class="major">Camera Calibration and Augmented Reality</h3>
											<p style="text-align: justify;">
												The aim of this project is to create a system that combines computer vision methods and augmented reality technology to project virtual objects onto real targets in a live video stream. The system utilizes a properly calibrated camera that tracks the pose of the target object by referencing the corners of the target. The chosen targets for this system are chessboards and Aruco boards. The cameras are calibrated by extracting corners from multiple images of a chessboard. Furthermore, a distinct program has been created to investigate the application of feature detection algorithms, such as Harris corners, in augmented reality.</p>
											<div style="display: flex; justify-content: space-between;">	
												<a href="pdf/Camera_claibration_and_AR.pdf" target="_blank"  class="special" style="margin-right: 10px;">Report</a>											
												<a href="https://github.com/arunmadhusud/Camera_Calibration_and_Augmented_Reality" target="_blank" class="special">GitHub</a>
											</div>
										</article>
										<article>
											<a href="pdf/State_estimation.pdf" target="_blank"  class="image"><img src="images/NTRIP .png" alt="" /></a>
											<h3 class="major">Robust Sensor Fusion System for State Estimation</h3>
											<p style="text-align: justify;">Understanding the state of the robot is a crucial
												element for autonomous navigation. Several papers investigate
												SLAM (Simultaneous Localization and Mapping) pipelines in
												either outdoor or interior contexts, or both. However, only a few
												works have looked at the difficulties that might develop when
												moving from an outdoor to an indoor setting or vice versa. In
												this project, we have explored some frequent problems faced
												when performing global state estimation during such environ-
												ment transitions using sensors such as Camera, IMU,
												and RTK-GPS. GVINS is a sensor fusion technique that combines data from different sensors such as camera, IMU, and RTK-GPS. By implementing GVINS, issues associated with each sensor were eliminated, resulting in accurate global state estimation for autonomous navigation in diverse environments.</p>
											<div style="display: flex; justify-content: space-between;">
												<a href="pdf/State_estimation.pdf" target="_blank"  class="special" style="margin-right: 10px;">Report</a>
												<a href="https://github.com/arunmadhusud/Sensor-Fusion-System-for-State-Estimation" target="_blank" class="special">GitHub</a>
											</div>
										</article>
										<article>
											<a href="pdf/IMU_Dead_Reckoning.pdf" target="_blank"  class="image"><img src="images/nuance.jpg" alt="" /></a>
											<h3 class="major">IMU Dead Reckoning</h3>
											<p style="text-align: justify;">This task involved constructing a simple navigation system using two sensors: a BU-353 GPS and a VectorNav VN-100 IMU. The primary objective was to calibrate and examine the IMU data. To gather data, the NUANCE car was driven around the campus, capturing both GPS and IMU measurements. The magnetometer was calibrated, and the collected data was combined with gyroscope data using a complementary filter. This fusion process resulted in a more precise determination of the sensor's orientation. Additionally, a dynamic bias correction was applied to the accelerometer using GPS velocity. The filtered estimates of yaw and position were then utilized for dead reckoning calculations.</p>
											<div style="display: flex; justify-content: space-between;">
												<a href="pdf/IMU_Dead_Reckoning.pdf" target="_blank"  class="special" style="margin-right: 10px;">Report</a>
												<a href="https://github.com/arunmadhusud/IMU-Dead-Reckoning" target="_blank" class="special">GitHub</a>
											</div>
										</article>
										
									<!-- </section>
									<ul class="actions">
										<li><a href="#" class="button">Browse All</a></li>
									</ul> -->
								</div>
							</section>
						<!-- Three -->
							<style>
								article {
									margin-bottom: 5px; /* Adjust the value as needed */
								}
							</style>
							
							<section id="three" class="wrapper spotlight style1">
								<div class="inner">
									<div class="content">
										<h2 class="major">Work Experience</h2>
							
										<article>
											<h3>Machine Learning Engineer Co-op, Festo USA, Boston | July 2023 - Dec 2023</h3>
											<p style="text-align: justify;">As a Machine Learning Engineer Co-op, I was involved in the development of a liquid dosing sensing unit as part of a 3-member team. Here is a summary of my primary responsibilities and achievements:</p>
							
											<ul style="text-align: justify;">
												<li><strong>Software Optimization:</strong> Optimized the software associated with the liquid dosing sensing unit, leading to increased efficiency and speed of the system. The software included modules for activating the sensing unit, hardware drivers for data acquisition, and modules for data conversion and storage.These enhancements significantly contributed to the seamless execution of experiments during the data collection phase.</li>
							
												<li><strong>Machine Learning Algorithm Development:</strong> Developed a machine learning algorithm to predict the system's behavior using readings from the sensing unit. Conducted experiments and analyses to identify data characteristics and experimented with various machine learning models, including Long Short-Term Memory cells, Temporal Convolutional Network, Neural Networks, as well as classical machine learning approaches like Decision Trees, Random Forests, AdaBoost, and Gradient Boosting. Leveraged various libraries such as PyTorch, SciPy, Scikit-learn, NumPy, and Pandas during this task.</li>
							
												<li><strong>Data Labeling and Performance Metrics:</strong> Post-processed collected data to extract relevant features, labeled extracted features for the machine learning task, and devised suitable performance metrics for comparing different machine learning models. Dedication to creating high-quality datasets and performance criteria contributed to enhancing the accuracy and reliability of machine learning models.</li>
							
												<li><strong>Live Inferencing Testing:</strong> Tested the developed machine learning model using live inferencing on a host PC connected to the system, resulting in an error rate of less than 2.5%.</li>

												<li><strong>Patent Application:</strong> The high-quality work I contributed resulted in a new technology that is now applied for a patent.</li>
											</ul>
										</article>
							
										<article>
											<h3>Wells Engineer, ExxonMobil, India | June 2018 - June 2022</h3>
											<p style="text-align: justify;">As a Wells Engineer, my primary responsibility was to design and select casing pipes and other equipment for installation in oil wells. I supported business divisions across the world in delivering fit-for-purpose and cost-effective tubular designs for over 15 fields and 60 wells. One of my key accomplishments was leading the beta testing of in-house casing and tubing design software, as well as third-party software DrillPlan, as a technical team lead.</p>
							
											<p style="text-align: justify;">Additionally, I stewarded and improved the tubular connection workflow for business divisions globally in accordance with API 5C5, resulting in $100k immediate savings and long-term synergistic benefits. Through a study that I led, the organizational change in the tubular design process resulted in $130k immediate savings and considerable synergistic savings through process simplification, greater standardization, and inventory transferability.</p>
							
											<p style="text-align: justify;">I also took the initiative to onboard and mentor Wells Engineers into technical projects while providing continuous guidance to them. These achievements demonstrate my technical expertise, leadership skills, and commitment to driving results that positively impact the organization.</p>
										</article>
									</div>
								</div>
							</section>
						<!-- Four -->
							<section id="four" class="wrapper alt style1">
								<div class="inner">									
									<div class="content">
										<h2 class="major">Publications</h2>
										<p><strong><a href="https://ieeexplore.ieee.org/abstract/document/9498443" target="_blank">Exoskeletal Development of a Hand Complex for Rehabilitation Activities</a></strong></p>										
										<p>2021 International Conference on Intelligent Technologies (CONIT 2021), IEEE, pp. 1-5</p>
										<p><strong><a href="https://www.sciencedirect.com/science/article/pii/S1877050918310111" target="_blank">Design, modelling and fabrication of railway track cleaning bot</a></strong></p>
										<p>ELSEVIER Procedia Computer Science, Volume 133, Pages 526-536, International Conference on Robotics and Smart Manufacturing (RoSMa2018). Received best paper award at conference</p>										
									</div>
								</div>
							</section>

					</section>

				<!-- Footer -->
					<section id="footer">
						<div class="inner">
							<!-- <h2 class="major">Get in touch</h2>
							<p>Cras mattis ante fermentum, malesuada neque vitae, eleifend erat. Phasellus non pulvinar erat. Fusce tincidunt, nisl eget mattis egestas, purus ipsum consequat orci, sit amet lobortis lorem lacus in tellus. Sed ac elementum arcu. Quisque placerat auctor laoreet.</p>
							<form method="post" action="#">
								<div class="fields">
									<div class="field">
										<label for="name">Name</label>
										<input type="text" name="name" id="name" />
									</div>
									<div class="field">
										<label for="email">Email</label>
										<input type="email" name="email" id="email" />
									</div>
									<div class="field">
										<label for="message">Message</label>
										<textarea name="message" id="message" rows="4"></textarea>
									</div>
								</div>
								<ul class="actions">
									<li><input type="submit" value="Send Message" /></li>
								</ul>
							</form>
							<ul class="contact">
								<li class="icon solid fa-home">
									Untitled Inc<br />
									1234 Somewhere Road Suite #2894<br />
									Nashville, TN 00000-0000
								</li>
								<li class="icon solid fa-phone">(000) 000-0000</li>
								<li class="icon solid fa-envelope"><a href="#">information@untitled.tld</a></li>
								<li class="icon brands fa-twitter"><a href="#">twitter.com/untitled-tld</a></li>
								<li class="icon brands fa-facebook-f"><a href="#">facebook.com/untitled-tld</a></li>
								<li class="icon brands fa-instagram"><a href="#">instagram.com/untitled-tld</a></li>
							</ul> -->
							<ul class="copyright">
								<li>&copy; Arun Madhusudhanan. All rights reserved.</li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
